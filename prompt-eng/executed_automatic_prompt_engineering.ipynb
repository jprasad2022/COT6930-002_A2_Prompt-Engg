{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec60571f",
   "metadata": {
    "papermill": {
     "duration": 0.002728,
     "end_time": "2025-02-21T02:58:03.172100",
     "exception": false,
     "start_time": "2025-02-21T02:58:03.169372",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb237f7",
   "metadata": {
    "papermill": {
     "duration": 0.001196,
     "end_time": "2025-02-21T02:58:03.175178",
     "exception": false,
     "start_time": "2025-02-21T02:58:03.173982",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Automatic Prompt Engineering\n",
    "\n",
    "Automatic Prompt Engineering refers to methods that automatically generate, refine, or optimize prompts for language models without relying solely on human intuition. Instead of manually crafting prompts through trial and error, these approaches use optimization techniques (such as gradient-based methods) or search strategies to discover prompts that effectively elicit the desired behavior from a model.\n",
    "\n",
    "One influential paper in this area is \"AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts\" by Shin et al. (2020). This work demonstrates how to automatically generate prompts that can tap into a language model’s latent knowledge by iteratively modifying discrete prompt tokens based on gradient signals. It’s a seminal work that has inspired further research into automated methods for prompt engineering.\n",
    "\n",
    "## References:\n",
    "* (Shin et al. (2020),)[https://arxiv.org/abs/2010.15980]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac98d1b",
   "metadata": {
    "papermill": {
     "duration": 0.00086,
     "end_time": "2025-02-21T02:58:03.177278",
     "exception": false,
     "start_time": "2025-02-21T02:58:03.176418",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "Note: remember that you will need to **adjust CONFIG** with **proper URL and API_KEY**!\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Fchain_of_thought.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3451e223",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2025-02-21T02:58:03.178151",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "# Define the prompt as a string variable using Automatic Prompt Engineering\n",
    "PROMPT = \"\"\"\n",
    "You are an expert in Automatic Prompt Engineering as well as in Surplus Lines Tax regulations across all 50 states.\n",
    "Your task is twofold:\n",
    "\n",
    "Step 1: Automatically design an optimal prompt that encapsulates all the necessary components for a comprehensive requirements analysis on Surplus Lines Tax regulations. The optimal prompt should include:\n",
    "- A general overview of the surplus lines tax regulatory framework.\n",
    "- Detailed, state-specific requirements such as tax rates, filing deadlines, and documentation mandates.\n",
    "- Information on compliance obligations, exemptions, and any unique conditions for each state.\n",
    "- Key challenges and considerations for businesses.\n",
    "\n",
    "Step 2: Without exposing any internal reasoning or the automatically generated prompt, use it to produce a final, well-organized, and comprehensive requirements analysis covering all 50 states.\n",
    "\n",
    "Your final output should only include the consolidated requirements analysis. Do not include any internal prompt engineering details or intermediate steps.\n",
    "\n",
    "Now, please design the optimal prompt internally and generate the final comprehensive requirements analysis for Surplus Lines Tax regulations.\n",
    "\"\"\"\n",
    "\n",
    "# You can then use this PROMPT variable with your LLM or orchestration setup\n",
    "print(PROMPT)\n",
    "\n",
    "# Count the number of words\n",
    "word_count = len(PROMPT.split())\n",
    "print(\"Number of words in the prompt:\", word_count)\n",
    "\n",
    "#### (3) Configure the Model request, simulating Workflow Orchestration\n",
    "# Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "payload = create_payload(target=\"ollama\",\n",
    "#                         model=\"deepseek-r1:14b\", \n",
    "                         model=\"phi4\",                         \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=0.3, \n",
    "                         num_ctx=word_count, \n",
    "                         num_predict=5000)\n",
    "\n",
    "### YOU DONT NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f'Time taken: {time}s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "automatic_prompt_engineering.ipynb",
   "output_path": "executed_automatic_prompt_engineering.ipynb",
   "parameters": {},
   "start_time": "2025-02-21T02:58:01.879359",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}