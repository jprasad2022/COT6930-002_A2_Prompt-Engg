{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Chaining\n",
    "Prompt chaining is a technique where you connect multiple prompts together in a sequence, with the output of one prompt serving as the input or context for the next. This approach breaks complex tasks into smaller, more manageable steps, allowing the language model to tackle each component separately and then synthesize a final answer. For instance, one prompt might generate a list of sub-tasks, and subsequent prompts use those sub-tasks to develop detailed answers or perform specific reasoning.\n",
    "\n",
    "While there isn’t a single canonical paper solely devoted to “prompt chaining,” its principles are closely related to chain-of-thought prompting and multi-step reasoning. One influential paper that underpins these ideas is \"Chain-of-Thought Prompting Elicits Reasoning in Large Language Models\" by Jason Wei et al. (2022), which demonstrates how prompting models to generate intermediate reasoning steps can improve performance on complex tasks. The concept of prompt chaining extends this idea by structuring a sequence of interactions that build upon each other.\n",
    "\n",
    "## References:\n",
    "* (Wei et al. (2022),)[https://arxiv.org/abs/2201.11903]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "Note: remember that you will need to **adjust CONFIG** with **proper URL and API_KEY**!\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Fchain_of_thought.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an expert in Surplus Lines Tax regulations across all 50 states.\n",
      "\n",
      "Before providing your final analysis, please think through the problem step by step:\n",
      "\n",
      "1. Identify the key components needed:\n",
      "   - An overview of the general regulatory framework.\n",
      "   - Specific details per state including tax rates, filing deadlines, and documentation requirements.\n",
      "   - Compliance obligations, exemptions, and any unique state-specific conditions.\n",
      "   - Common challenges or considerations for businesses operating under these regulations.\n",
      "\n",
      "2. As an example, think through the analysis for one state (e.g., California):\n",
      "   - Step 1: Determine the core regulatory requirements.\n",
      "   - Step 2: Break down the details such as tax rate, filing deadline, and required documents.\n",
      "   - Step 3: Identify any special conditions or exemptions.\n",
      "   - Step 4: Summarize these findings concisely.\n",
      "\n",
      "3. Now, using this step-by-step reasoning, generate a comprehensive requirements analysis covering all 50 states.\n",
      "   - Structure your final answer clearly by state or by regulatory theme.\n",
      "   - Ensure your analysis is detailed and well-organized.\n",
      "\n",
      "Include your internal chain-of-thought reasoning in your response, followed by the final structured analysis.\n",
      "\n",
      "<think>\n",
      "Alright, I'm trying to figure out how to approach this user's query. They want me to generate a detailed report on data privacy laws across all 50 states in the US, organized either by state or by regulatory themes. The previous response was a structured overview divided into sections like State-Specific Laws, General Themes of Data Privacy Law, and Federal vs. State Jurisdiction.\n",
      "\n",
      "First, I need to understand the user's intent. They're likely looking for a comprehensive yet concise\n",
      "Time taken: 41.025s\n"
     ]
    }
   ],
   "source": [
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "# Define the chained prompt as a string variable\n",
    "\n",
    "PROMPT = \"\"\"\n",
    "[Step 1: Identify Key Components]\n",
    "You are an expert on Surplus Lines Tax regulations across all 50 states.\n",
    "First, list all the key components that should be included in a comprehensive requirements analysis for these regulations. Consider including:\n",
    "- An overview of the general regulatory framework for surplus lines tax.\n",
    "- Specific details for each state such as tax rates, filing deadlines, and documentation requirements.\n",
    "- Compliance obligations, exemptions, and any unique state-specific conditions.\n",
    "- Challenges and considerations for businesses operating under these regulations.\n",
    "\n",
    "[Step 2: Write Comprehensive Analysis]\n",
    "Using the key components you identified in Step 1, now produce a detailed and well-organized requirements analysis for Surplus Lines Tax regulations covering all 50 states.\n",
    "- Organize your analysis by state or by regulatory theme.\n",
    "- Ensure that your analysis is detailed, accurate, and concise.\n",
    "- Provide only the final consolidated analysis without showing the intermediate list.\n",
    "\n",
    "Final Instruction:\n",
    "Please provide only the final comprehensive requirements analysis as your answer.\n",
    "\"\"\"\n",
    "\n",
    "# You can then use this PROMPT variable with your LLM or orchestration setup\n",
    "print(PROMPT)\n",
    "\n",
    "\n",
    "# Count the number of words\n",
    "word_count = len(PROMPT.split())\n",
    "print(\"Number of words in the prompt:\", word_count)\n",
    "\n",
    "#### (3) Configure the Model request, simulating Workflow Orchestration\n",
    "# Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "payload = create_payload(target=\"ollama\",\n",
    "#                         model=\"deepseek-r1:14b\", \n",
    "                         model=\"phi4\",                         \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=0.3, \n",
    "                         num_ctx=word_count, \n",
    "                         num_predict=5000)\n",
    "\n",
    "### YOU DONT NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f'Time taken: {time}s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
