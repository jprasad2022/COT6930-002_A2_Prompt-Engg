{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directional Stimulus Prompting\n",
    "Directional Stimulus Prompting is an approach where the prompt is deliberately augmented with cues or directives that \"steer\" the model’s output in a particular direction. In this framework, the prompt includes additional stimulus—such as keywords, phrases, or specific instructions—that act as directional signals to guide the model toward a desired style, tone, or content focus. This technique is especially useful when you want to constrain the generation process, ensuring that the output adheres to particular criteria or covers specific aspects.\n",
    "\n",
    "While the precise term \"Directional Stimulus Prompting\" is not yet widely established as a standalone concept in the literature, similar ideas appear in research on controlled text generation and prompt tuning. One related paper is \"Prefix-Tuning: Optimizing Continuous Prompts for Generation\" by Li and Liang (2021). In this work, the authors demonstrate how introducing learnable continuous prompts (which can be viewed as directional cues) effectively guides the model’s output without updating the full model parameters. Although not labeled explicitly as \"Directional Stimulus Prompting,\" this paper provides insights into how additional prompt components can steer generation in a controlled manner.\n",
    "\n",
    "## References:\n",
    "* (Li and Liang (2021),)[https://arxiv.org/abs/2101.00190]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "Note: remember that you will need to **adjust CONFIG** with **proper URL and API_KEY**!\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Fchain_of_thought.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an expert on Surplus Lines Tax regulations across all 50 states. You are using an Active-Prompt approach, which means you should actively verify your understanding and, if necessary, ask clarifying questions before generating your final output.\n",
      "\n",
      "Step 1: Confirm the key components required for a comprehensive requirements analysis:\n",
      "- A general overview of the surplus lines tax regulatory framework.\n",
      "- Detailed, state-specific requirements including tax rates, filing deadlines, and documentation mandates.\n",
      "- Information on compliance obligations, exemptions, and any unique conditions for each state.\n",
      "- Key challenges and considerations for businesses operating under these regulations.\n",
      "\n",
      "Step 2: If any part of the task or details are unclear, ask a clarifying question to ensure accuracy. Otherwise, proceed with generating a detailed and well-organized analysis, structured by state or regulatory theme.\n",
      "\n",
      "Step 3: Provide only the final consolidated requirements analysis for Surplus Lines Tax regulations, incorporating any necessary active adjustments based on your review.\n",
      "\n",
      "Now, please confirm your understanding (by asking any clarifying questions if needed) and then generate the final comprehensive requirements analysis for Surplus Lines Tax regulations.\n",
      "\n",
      "<think>\n",
      "Alright, I need to confirm my understanding of the user's request. They mentioned that they want me to first ask any clarifying questions about their instructions regarding generating a comprehensive requirements analysis for Surplus Lines Tax regulations. Then, after receiving any necessary clarification, I should proceed to create this analysis.\n",
      "\n",
      "So, in the previous message, I asked if \"You are referring to U.S. state-specific surplus lines tax regulations...\" and if they want me to address something specific like an appeal process or\n",
      "Time taken: 39.821s\n"
     ]
    }
   ],
   "source": [
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "# Define the prompt as a string variable using Directional Stimulus Prompting\n",
    "PROMPT = \"\"\"\n",
    "You are an expert on Surplus Lines Tax regulations across all 50 states. Your task is to produce a comprehensive requirements analysis for these regulations.\n",
    "\n",
    "[Directional Stimulus]\n",
    "Please structure your final analysis with the following components:\n",
    "1. **General Overview:** Provide a concise summary of the surplus lines tax regulatory framework.\n",
    "2. **State-Specific Details:** For each state, list the key regulatory requirements, including:\n",
    "   - Tax rates\n",
    "   - Filing deadlines\n",
    "   - Documentation mandates\n",
    "3. **Compliance and Exemptions:** Describe compliance obligations, available exemptions, and any unique state-specific conditions.\n",
    "4. **Business Considerations:** Highlight common challenges and considerations for businesses operating under these regulations.\n",
    "\n",
    "[Output Direction]\n",
    "- Organize your response either by state or by grouping related regulatory themes.\n",
    "- Use clear headings, bullet points, or numbered lists for clarity.\n",
    "- Ensure the analysis is detailed, accurate, and concise.\n",
    "\n",
    "Now, please produce the final, consolidated requirements analysis for Surplus Lines Tax regulations.\n",
    "\"\"\"\n",
    "\n",
    "# You can then use this PROMPT variable in your LLM or orchestration setup\n",
    "print(PROMPT)\n",
    "\n",
    "# Count the number of words\n",
    "word_count = len(PROMPT.split())\n",
    "print(\"Number of words in the prompt:\", word_count)\n",
    "\n",
    "#### (3) Configure the Model request, simulating Workflow Orchestration\n",
    "# Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "payload = create_payload(target=\"ollama\",\n",
    "#                         model=\"deepseek-r1:14b\", \n",
    "                         model=\"phi4\",                         \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=0.3, \n",
    "                         num_ctx=word_count, \n",
    "                         num_predict=5000)\n",
    "\n",
    "### YOU DONT NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f'Time taken: {time}s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
